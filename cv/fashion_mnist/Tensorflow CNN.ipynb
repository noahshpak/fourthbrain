{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "protected-amber",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "IMAGE_SIZE = 28\n",
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 40\n",
    "\n",
    "raw_train = pd.read_csv(\"fashion-mnist_train.csv\")\n",
    "raw_test = pd.read_csv(\"fashion-mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "hourly-macro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0        30        43         0   \n",
       "3       0  ...         3         0         0         0         0         1   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "understood-graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(raw_df):\n",
    "    labels, images = raw_df.iloc[:, 0].values, raw_df.iloc[:, 1:].values\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "abandoned-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = transform(raw_train)\n",
    "test_x, test_y = transform(raw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "meaning-spirit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_train[\"label\"].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "spatial-scratch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(images, labels, training=True, reshape=True):\n",
    "    if reshape:\n",
    "        images = images.reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 1)\n",
    "    one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=NUM_CLASSES)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(((images), (one_hot_labels)))\n",
    "    if training:\n",
    "        ds = ds.shuffle(buffer_size=1024, reshuffle_each_iteration=True)\n",
    "    ds = ds.batch(batch_size=BATCH_SIZE)\n",
    "    return ds  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "automotive-connection",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = create_dataset(train_x, train_y, reshape=False)\n",
    "test_ds = create_dataset(test_x, test_y, reshape=False, training=False)\n",
    "\n",
    "train_ds_cnn = create_dataset(train_x, train_y, reshape=True)\n",
    "test_ds_cnn = create_dataset(train_x, train_y, reshape=True, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "becoming-cotton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((None, 784), (None, 10)), types: (tf.int64, tf.float32)>"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "supported-karaoke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((None, 28, 28, 1), (None, 10)), types: (tf.int64, tf.float32)>"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_cnn.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "lucky-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoders = [\n",
    "            tf.keras.layers.Dense(units, activation=tf.nn.relu) for units in (1024, 512, 256)\n",
    "        ]\n",
    "        self.softmax = tf.keras.layers.Dense(NUM_CLASSES, activation=tf.nn.softmax)\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        hidden = self.encoders[0](inputs)\n",
    "        for l in self.encoders[1:]:\n",
    "            hidden = l(hidden)\n",
    "        return self.softmax(hidden)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "needed-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseModel()\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "protective-progress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1649d1490>"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_ds, use_multiprocessing=True, verbose=False, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "recovered-dutch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 3ms/step - loss: 1.7226 - accuracy: 0.1999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7226057052612305, 0.19990000128746033]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=test_ds, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "pregnant-airport",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.preprocess = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
    "        self.augmentation = tf.keras.Sequential([\n",
    "          tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "          tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "        ])\n",
    "        self.encoders = [\n",
    "            tf.keras.layers.BatchNormalization(trainable=tf.keras.backend.learning_phase()),\n",
    "            tf.keras.layers.Conv2D(8, 2),\n",
    "            tf.keras.layers.BatchNormalization(trainable=tf.keras.backend.learning_phase()),\n",
    "            tf.keras.layers.Activation(\"relu\"),\n",
    "            tf.keras.layers.Conv2D(16, 3),\n",
    "            tf.keras.layers.BatchNormalization(trainable=tf.keras.backend.learning_phase()),\n",
    "            tf.keras.layers.Activation(\"relu\"),\n",
    "            tf.keras.layers.Conv2D(32, 3),\n",
    "            tf.keras.layers.BatchNormalization(trainable=tf.keras.backend.learning_phase()),\n",
    "            tf.keras.layers.Activation(\"relu\"),\n",
    "            tf.keras.layers.Conv2D(64, 3),\n",
    "            tf.keras.layers.BatchNormalization(trainable=tf.keras.backend.learning_phase()),\n",
    "            tf.keras.layers.Activation(\"relu\"),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            tf.keras.layers.Conv2D(128, 2),\n",
    "            tf.keras.layers.BatchNormalization(trainable=tf.keras.backend.learning_phase()),\n",
    "            tf.keras.layers.Activation(\"relu\"),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            \n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            tf.keras.layers.Flatten()\n",
    "        ]\n",
    "        self.logits = tf.keras.layers.Dense(32, activation='relu')\n",
    "        self.softmax = tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        inputs = self.preprocess(inputs)\n",
    "        if training: \n",
    "            inputs = self.augmentation(inputs)\n",
    "        \n",
    "        hidden = self.encoders[0](inputs)\n",
    "        for layer in self.encoders[1:]:\n",
    "            hidden = layer(hidden)\n",
    "        logits = self.logits(hidden)\n",
    "        return self.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "residential-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = CNNModel()\n",
    "cnn_model.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0033),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "recognized-description",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1500/1500 [==============================] - 117s 78ms/step - loss: 0.9385 - accuracy: 0.6552\n",
      "Epoch 2/25\n",
      "1500/1500 [==============================] - 120s 80ms/step - loss: 0.7276 - accuracy: 0.7336\n",
      "Epoch 3/25\n",
      "1500/1500 [==============================] - 122s 81ms/step - loss: 0.6609 - accuracy: 0.7588\n",
      "Epoch 4/25\n",
      "1500/1500 [==============================] - 126s 84ms/step - loss: 0.6253 - accuracy: 0.7739\n",
      "Epoch 5/25\n",
      "1500/1500 [==============================] - 117s 78ms/step - loss: 0.5961 - accuracy: 0.7864\n",
      "Epoch 6/25\n",
      "1500/1500 [==============================] - 166s 111ms/step - loss: 0.5821 - accuracy: 0.7904\n",
      "Epoch 7/25\n",
      "1500/1500 [==============================] - 176s 117ms/step - loss: 0.5728 - accuracy: 0.7935\n",
      "Epoch 8/25\n",
      "1500/1500 [==============================] - 167s 111ms/step - loss: 0.5567 - accuracy: 0.8004\n",
      "Epoch 9/25\n",
      "1500/1500 [==============================] - 146s 97ms/step - loss: 0.5531 - accuracy: 0.8015\n",
      "Epoch 10/25\n",
      "1500/1500 [==============================] - 170s 114ms/step - loss: 0.5417 - accuracy: 0.8064\n",
      "Epoch 11/25\n",
      " 984/1500 [==================>...........] - ETA: 1:01 - loss: 0.5391 - accuracy: 0.8039"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-372-08c82b47b833>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_ds_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/fourthbrain/linear_regression/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/fourthbrain/linear_regression/venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/fourthbrain/linear_regression/venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/fourthbrain/linear_regression/venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/fourthbrain/linear_regression/venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/fourthbrain/linear_regression/venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/code/fourthbrain/linear_regression/venv/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cnn_model.fit(x=train_ds_cnn, use_multiprocessing=True, epochs=25, verbose=1)\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "elder-expense",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.4294 - accuracy: 0.8490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4293837249279022, 0.8489833474159241]"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.evaluate(x=test_ds_cnn, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-simple",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-spyware",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
