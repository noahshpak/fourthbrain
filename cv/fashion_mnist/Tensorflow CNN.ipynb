{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vulnerable-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "IMAGE_SIZE = 28\n",
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 40\n",
    "\n",
    "raw_train = pd.read_csv(\"fashion-mnist_train.csv\")\n",
    "raw_test = pd.read_csv(\"fashion-mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "encouraging-spectrum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0        30        43         0   \n",
       "3       0  ...         3         0         0         0         0         1   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "underlying-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(raw_df):\n",
    "    labels, images = raw_df.iloc[:, 0].values, raw_df.iloc[:, 1:].values\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pressed-chancellor",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = transform(raw_train)\n",
    "test_x, test_y = transform(raw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "engaging-impossible",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_train[\"label\"].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "latter-mercy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(images, labels, training=True, reshape=True):\n",
    "    if reshape:\n",
    "        images = images.reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 1)\n",
    "    one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=NUM_CLASSES)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(((images), (one_hot_labels)))\n",
    "    if training:\n",
    "        ds = ds.shuffle(buffer_size=1024, reshuffle_each_iteration=True)\n",
    "    ds = ds.batch(batch_size=BATCH_SIZE)\n",
    "    return ds  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "northern-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = create_dataset(train_x, train_y, reshape=False)\n",
    "test_ds = create_dataset(test_x, test_y, reshape=False, training=False)\n",
    "\n",
    "train_ds_cnn = create_dataset(train_x, train_y, reshape=True)\n",
    "test_ds_cnn = create_dataset(train_x, train_y, reshape=True, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "wound-brisbane",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((None, 784), (None, 10)), types: (tf.int64, tf.float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "growing-membership",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((None, 28, 28, 1), (None, 10)), types: (tf.int64, tf.float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_cnn.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "connected-wayne",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.preprocess = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
    "        self.encoders = [\n",
    "            tf.keras.layers.BatchNormalization(trainable=tf.keras.backend.learning_phase()),\n",
    "            *[tf.keras.layers.Dense(units, activation=tf.nn.relu) for units in (28, 56, 84)]\n",
    "        ]\n",
    "        self.softmax = tf.keras.layers.Dense(NUM_CLASSES, activation=tf.nn.softmax)\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        inputs = self.preprocess(inputs)\n",
    "        hidden = self.encoders[0](inputs)\n",
    "        for l in self.encoders[1:]:\n",
    "            hidden = l(hidden)\n",
    "        return self.softmax(hidden)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "black-webmaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseModel()\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "timely-hebrew",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x166684cd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_ds, use_multiprocessing=True, verbose=False, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "attended-blues",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 922us/step - loss: 0.4171 - accuracy: 0.8564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4170991778373718, 0.8564000129699707]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=test_ds, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "existing-relation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.preprocess = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
    "        self.encoders = [\n",
    "            tf.keras.layers.BatchNormalization(trainable=tf.keras.backend.learning_phase()),\n",
    "            tf.keras.layers.Conv2D(32, 3),\n",
    "            tf.keras.layers.Activation(\"relu\"),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            tf.keras.layers.BatchNormalization(trainable=tf.keras.backend.learning_phase()),\n",
    "            tf.keras.layers.Conv2D(64, 3),\n",
    "            tf.keras.layers.Activation(\"relu\"),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            tf.keras.layers.Flatten(),\n",
    "        ]\n",
    "        self.logits = tf.keras.layers.Dense(128, activation='relu',  kernel_initializer='he_uniform')\n",
    "\n",
    "        self.softmax = tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        inputs = self.preprocess(inputs)        \n",
    "        hidden = self.encoders[0](inputs)\n",
    "        for layer in self.encoders[1:]:\n",
    "            hidden = layer(hidden)\n",
    "        logits = self.logits(hidden)\n",
    "        return self.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "initial-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = CNNModel()\n",
    "cnn_model.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "loved-unknown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling_3 (Rescaling)      multiple                  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch multiple                  4         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            multiple                  320       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch multiple                  128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            multiple                  18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              multiple                  204928    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              multiple                  1290      \n",
      "=================================================================\n",
      "Total params: 225,166\n",
      "Trainable params: 225,034\n",
      "Non-trainable params: 132\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.fit(x=train_ds_cnn, use_multiprocessing=True, epochs=25, verbose=0)\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "willing-homework",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 9s 5ms/step - loss: 0.2305 - accuracy: 0.9141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23046399652957916, 0.9141166806221008]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.evaluate(x=test_ds_cnn, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-auckland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-intelligence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
